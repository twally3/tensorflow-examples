{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Tensorflow\n",
    "Logistic regression is a statistical method of analyzing a dataset with one or more independant variables. It differs from linear regression where by the dependent variable is limited to a certain set of outputs. Here we will be using logistic regression to classify a set of handwritten digits from the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "First import tensorflow. Then we need to import the MNIST dataset. Tensorflow makes this simple as it is part of the tf library.\n",
    "\n",
    "### One Hot Encoding\n",
    "You may notice that when we are reading the datasets we set a parameter called one_hot to true. One hot encoding is generally used for classification. A one hot encoded set of outputs has a bit that can be either 0 or 1 for each output. In this case we have the numbers 0-9 we therefore have 10 output values where 4 is reprisented as \n",
    ">[0,0,0,0,1,0,0,0,0,0]\n",
    "\n",
    "This is done to make it easier for the network to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the data\n",
    "It's always good to get familliar with your data. Using matplotlib (the saving grace of anything graphical) the data from MNIST can be rendered on a graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10446a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Function for displaying a training image by it's index in the MNIST set\n",
    "def show_digit(index):\n",
    "#     label = trainY[index].argmax(axis=0)\n",
    "    # Reshape 784 array into 28x28 image\n",
    "#     image = trainX[index].reshape([28,28])\n",
    "    label = mnist.train.labels[index].argmax(axis=0)\n",
    "    image = mnist.train.images[index].reshape([28, 28])\n",
    "    plt.title('Training data, index: %d,  Label: %d' % (index, label))\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()\n",
    "    \n",
    "# Display the first (index 0) training image\n",
    "show_digit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well here we are again (it's always such a pleasure)\n",
    "Next we define the hyperparameters. You may notice we have a new one amongst us. The batch size. This is the max number of that will be passed into the network at once. It is much less memory intensive to pass smaller batches throught the network rather than each one at once. It also allows the network to train faster as the weights are updated for each batch per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our data properties\n",
    "It's always good practice to define our data's parameters. It shows that we have understood how our data works and it is simple as we will be referencing them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 784 #28 * 28 = 784 The same of the MNIST images\n",
    "n_classes = 10 #One hot encoded 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "To build the model we define placeholders for the input and output layers and their respective sizes. We now have multiple weights and biases which we initialise as 0 matricies of shapes 784 * 10 and 10 respectively. \n",
    "\n",
    "Each node in the input layer connects to each node in the output layer. For a given output node we take the values for each input layer and multiply that by each weight that connects to that output layer and add them together to get the value. This is done for each output layer and each connection has its own set of weights\n",
    "\n",
    "![alt](http://neuroph.sourceforge.net/tutorials/images/perceptron.jpg)\n",
    "\n",
    "Finally we use the softmax activation function to calculate the probablilty of what the output will be. Softmax takes each output value and compresses them such that their total sum adds to one.\n",
    "\n",
    "![alt](https://jamesmccaffrey.files.wordpress.com/2016/03/softmaxequation.jpg?w=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, n_inputs]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, n_classes]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([n_inputs, n_classes]))\n",
    "b = tf.Variable(tf.zeros([n_classes]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and reduce the error\n",
    "Just like before we use Cross Entropy to calculate the cost and optimise in the same way as before. Cross Entropy is just another function for calculating the cost. It is for calculating the error for each item in the vector outputted by softmax\n",
    "![alt](https://d17h27t6h515a5.cloudfront.net/topher/2017/February/589b18f5_cross-entropy-diagram/cross-entropy-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 1.182138980\n",
      "Epoch: 0002 cost= 0.664828202\n",
      "Epoch: 0003 cost= 0.552770787\n",
      "Epoch: 0004 cost= 0.498630970\n",
      "Epoch: 0005 cost= 0.465495543\n",
      "Epoch: 0006 cost= 0.442459152\n",
      "Epoch: 0007 cost= 0.425508859\n",
      "Epoch: 0008 cost= 0.412122641\n",
      "Epoch: 0009 cost= 0.401368072\n",
      "Epoch: 0010 cost= 0.392369696\n",
      "Epoch: 0011 cost= 0.384760975\n",
      "Epoch: 0012 cost= 0.378156591\n",
      "Epoch: 0013 cost= 0.372398087\n",
      "Epoch: 0014 cost= 0.367266582\n",
      "Epoch: 0015 cost= 0.362763758\n",
      "Epoch: 0016 cost= 0.358615950\n",
      "Epoch: 0017 cost= 0.354888233\n",
      "Epoch: 0018 cost= 0.351408012\n",
      "Epoch: 0019 cost= 0.348339124\n",
      "Epoch: 0020 cost= 0.345408297\n",
      "Epoch: 0021 cost= 0.342743186\n",
      "Epoch: 0022 cost= 0.340257424\n",
      "Epoch: 0023 cost= 0.337887060\n",
      "Epoch: 0024 cost= 0.335766784\n",
      "Epoch: 0025 cost= 0.333713177\n",
      "Optimization Finished!\n",
      "Accuracy: 0.887333\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print (\"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Using a single layer neural network we have predicted the value of a handwritten digit using logistic regression with an accuracy of 88.7%. Now we can add more layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
