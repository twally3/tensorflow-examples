{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Linear Regression Model\n",
    "Okay, so this isn't quite a neural network yet but it is important that you understand whats going on here, as it is the basis of all neural networks. We will be using tensorflow for linear regression, in laymans terms, drawing a line of best fit.\n",
    "\n",
    "Regression is the process of recogising a trend the the data and being able to predict future values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we need to import our dependencies\n",
    "First we import tensorflow as always. \n",
    "Next we import numpy, numpy is a fantastic library for more advanced maths. You can find the documentation [here](http://www.numpy.org)\n",
    "Finally we are importing pyplot from matplotlib just so we can draw our graph at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "You will soon learn that these numbers will eventually become the bane of your existance. Hyperparameters are essentially the conceptual tuning knobs for our network. Changing them allows us to improve the accuracy of our final result.\n",
    "\n",
    "Learning Rate: The rate at which the network learns during gradient descent. You may want to just make this number huge but hold on a sec. If the learning rate is too small the network will train too slowly, too big and you will completely overshoot the optimal gradient. Mathematically speaking, it is the size of the step taken when we are trying to move down the gradient.\n",
    "\n",
    "training epochs: the number of iterations for training. Too few and you won't learn enough. Too many and you risk overfitting.\n",
    "\n",
    "display step: just for our aesthetical purposes. It is how many epochs should pass before we display the current status of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Next we need to get the data from the data.csv file into python. We will use numpys genfromtxt function to load the data then iterate through it to seperate the x and the y data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.genfromtxt('data.csv', delimiter=\",\")\n",
    "x = list()\n",
    "y = list()\n",
    "for i in range(0, len(points)):\n",
    "    x.append(points[i, 0])\n",
    "    y.append(points[i, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32.50234527,  31.70700585],\n",
       "       [ 53.42680403,  68.77759598],\n",
       "       [ 61.53035803,  62.5623823 ],\n",
       "       [ 47.47563963,  71.54663223],\n",
       "       [ 59.81320787,  87.23092513]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the data and convert them into numpy arrays and get the number of samples for the cost calculation later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = np.asarray(x)\n",
    "train_Y = np.asarray(y)\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Placeholders\n",
    "Next we need to set up placeholders for the x and y values. As we know these values are float types we will use tf.float32 to define the type. \n",
    "\n",
    "We are now going to use tf.Variable(s) to store the weights and the biases. The tf.Variable method is given a value when it is initialized. However unlike tf.constant its values can be changed. \n",
    "\n",
    "Here we will initialize the weight and bias as random numbers from the numpy.random.randn method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(np.random.randn(), name=\"weight\")\n",
    "b = tf.Variable(np.random.randn(), name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights and biases?\n",
    "Weights and biases are additional tuning knobs to help the network reach convergance (the most optimal state). The difference between these values are that they are automatically adjusted by the network during optimisation. This is where the learning happens.\n",
    "\n",
    "Remember the equation of a straight line from school: y = mx + b\n",
    "\n",
    "Well here the weight value is the gradient (m) and the bias are the y-intercept (b) With these two properties the line can be transformed in any way. We can therefore adjust these values to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.add(tf.mul(X, W), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "Next, it's time to make the network learn. Humans learn through trial and error. The more we try, the more we improve. This principle also applies to our learning technique. First we plot the line. Then we work out how wrong our line is. We do this using the Mean Squared Error\n",
    "![alt](http://www.aoml.noaa.gov/hrd/Landsea/artificial/equa-4)\n",
    "We then use something called gradient descent to work out by how much we need to adjust our weights and biases to be more accurate i.e. minimise the error value. This is calculated using partial derivatives. We take the change in the Error with respect to the weight and the bias values for each node. In this case we only have one weight and one bias\n",
    "![alt](https://spin.atomicobject.com/wp-content/uploads/gradient_descent_error_by_iteration.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's session time!\n",
    "Now we have done all the maths its time to run the session. When using tf.Variables remember to always initialise them in the current graph (session).\n",
    "\n",
    "We iterate for our specified number of epochs. Within this loop, we loop through each x and corresponding y values for optimisation. To optimise, pass the optimiser variable into the session and give it the x and y data through the feed dict.\n",
    "\n",
    "Everything else is just to display cost and other values to us while we learn. Just so we can make sure it is learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 68.277984619 W= 1.56078 b= 0.899695\n",
      "Epoch: 0100 cost= 68.220703125 W= 1.55826 b= 1.02268\n",
      "Epoch: 0150 cost= 68.165046692 W= 1.55579 b= 1.14327\n",
      "Epoch: 0200 cost= 68.111083984 W= 1.55337 b= 1.26153\n",
      "Epoch: 0250 cost= 68.058670044 W= 1.551 b= 1.37749\n",
      "Epoch: 0300 cost= 68.007804871 W= 1.54867 b= 1.4912\n",
      "Epoch: 0350 cost= 67.958366394 W= 1.54639 b= 1.60271\n",
      "Epoch: 0400 cost= 67.910469055 W= 1.54415 b= 1.71205\n",
      "Epoch: 0450 cost= 67.863914490 W= 1.54196 b= 1.81927\n",
      "Epoch: 0500 cost= 67.818679810 W= 1.5398 b= 1.92441\n",
      "Epoch: 0550 cost= 67.774765015 W= 1.53769 b= 2.02751\n",
      "Epoch: 0600 cost= 67.732063293 W= 1.53562 b= 2.12861\n",
      "Epoch: 0650 cost= 67.690673828 W= 1.5336 b= 2.22774\n",
      "Epoch: 0700 cost= 67.650367737 W= 1.53161 b= 2.32495\n",
      "Epoch: 0750 cost= 67.611289978 W= 1.52965 b= 2.42028\n",
      "Epoch: 0800 cost= 67.573219299 W= 1.52774 b= 2.51376\n",
      "Epoch: 0850 cost= 67.536308289 W= 1.52586 b= 2.60543\n",
      "Epoch: 0900 cost= 67.500411987 W= 1.52403 b= 2.69531\n",
      "Epoch: 0950 cost= 67.465484619 W= 1.52222 b= 2.78345\n",
      "Epoch: 1000 cost= 67.431541443 W= 1.52045 b= 2.86988\n",
      "Optimization Finished!\n",
      "Training cost= 67.4315 W= 1.52045 b= 2.86988 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d4a3c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print (\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "That't it you have created a program that can learn on its own. The principles in this project are applied for all neural networks as you will soon learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
